# Machine Learning Algorithms

Machine Learning (ML) algorithms are mathematical models or computational techniques used to make predictions, classify data, or recognize patterns in datasets. They can be broadly categorized into two types: **Supervised Learning** and **Unsupervised Learning**.

## 1. Supervised Learning

Supervised learning algorithms learn from labeled data, meaning that each training example is paired with a correct output. The goal is for the algorithm to learn a mapping from inputs to outputs, so it can make predictions on new, unseen data. 

### Common Supervised Learning Algorithms:
- **Linear Regression**: Used for predicting a continuous value (e.g., predicting house prices).
- **Logistic Regression**: Used for binary classification tasks (e.g., spam detection).
- **Decision Trees**: Models that split the data into subsets based on feature values, forming a tree-like structure.
- **Random Forest**: An ensemble method that combines multiple decision trees to improve accuracy and reduce overfitting.
- **Support Vector Machines (SVM)**: A classifier that finds a hyperplane which best separates the classes.
- **K-Nearest Neighbors (KNN)**: A non-parametric method that classifies data points based on the majority class of the k closest neighbors.
- **Neural Networks**: A class of algorithms inspired by the structure and functioning of the human brain, used for complex tasks like image recognition and natural language processing.

### Key Features of Supervised Learning:
- Requires labeled data.
- Aims to learn a mapping function from input data to the correct output.
- Commonly used in classification and regression tasks.

## 2. Unsupervised Learning

Unsupervised learning algorithms work with data that does not have labeled outcomes. Instead, these algorithms try to identify patterns, groupings, or structures within the data without prior knowledge of what the outputs should be.

### Common Unsupervised Learning Algorithms:
- **K-Means Clustering**: An algorithm that divides data into k clusters by minimizing the variance within each cluster.
- **Hierarchical Clustering**: Builds a tree-like structure of clusters and can be either agglomerative (bottom-up) or divisive (top-down).
- **Principal Component Analysis (PCA)**: A dimensionality reduction technique that transforms data into a lower-dimensional space while retaining the most variance.
- **Gaussian Mixture Model (GMM)**: A probabilistic model that assumes all the data points are generated from a mixture of several Gaussian distributions.
- **Autoencoders**: Neural networks used for unsupervised learning tasks, often for dimensionality reduction or feature extraction.

### Key Features of Unsupervised Learning:
- Does not require labeled data.
- Aims to find patterns, structures, or relationships within the data.
- Commonly used in clustering, anomaly detection, and dimensionality reduction tasks.

## Conclusion

Machine learning algorithms play a pivotal role in enabling computers to learn from data. The choice of algorithm depends on the type of data available and the problem to be solved. **Supervised learning** is ideal for tasks where you have labeled data and a specific prediction task, whereas **unsupervised learning** is better suited for exploring and understanding the underlying structure of data without predefined labels.
